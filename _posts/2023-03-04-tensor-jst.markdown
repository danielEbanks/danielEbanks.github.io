---
layout: post
title:  Tensor-Based Implementation for Joint Sentiment Topic Modeling 
description: Methods for Large Scale Text Data
date:   2023-03-05 15:01:35 +0300
author: danny
image:  '/images/MDS.jpg#wide'
tags:   [tensors,nlp,topic-modeling,congress]
tags_color: '#477010'
---

<b>Authors:</b> Daniel Ebanks, Nick Adams Cohen, R. Michael Alvarez <br>


## Abstract

 This paper makes two key  contributions -- one is linking an estimation method to a machine learning method in a novel way. Second is applying this method to empirical social science questions related to the U.S. House of Representatives and their partisan positioning on social media.  This paper estimates a latent variable model of sentiment and topic, jointly, using tensor-based spectral decomposition, to recover the eigenvectors and eigenvalues of low-order moments of the model. This is the attempt to link Joint Sentiment Topic (JST) estimation to spectral methods (usually, researchers estimate JST using Expectation Maximization or Gibbs Sampling). This method addresses the key implementation issue of computational tractability of topic modeling methods, while making use of implementation choices that reduce memory overhead in a way that makes the method usable on standard workstations. We then fit this model to social media data related to U.S. House of Representatives. We apply the model to Twitter data generated by House members and compare the results to traditional methods (Latent Dirchilet Allocation, JST using Gibs Sampling), and we show that JST with tensor-based methods successfully recovers both facially understandable sentiment-topic labels, as well as known political structure (i.e. partisan policy stances)  more quickly than the traditional methods while achieving higher scores in measures of topical coherence over Latent Dirichlet Allocation . 